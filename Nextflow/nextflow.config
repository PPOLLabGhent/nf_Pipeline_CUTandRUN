nextflow.enable.dsl=2
// These lines with two slashes in from of them are comment lines.
cleanup=true

// The main parameters, these serve as input variables for the pipeline.
// Standard modifications are made in the block below.
params{
    
    // pathBase serves as a basis for the subvariables beneath it.
    // input, data and results key off of it so i don't have to update all of them individually.
    // You can use absolute paths instead if you so wish to.
    pathBase="/data/gent/gvo000/gvo00027/PPOL/resources/sharedData/CUTandRUN_BDC_SLB"
    
    // directory with the three required inputs.
    inputDir = "/data/gent/gvo000/gvo00027/PPOL/resources/sharedData/CUTandRUN_BDC_SLB/FASTQfiles/$params.RunName" 
    
    // The output directory where the data is published (in their own directories).
    dataDir = "$pathBase/Data" 
    
    // The output directory where the results are published (in their respective directories).
    resultsDir = "$pathBase/Results" 

    // The sequence length by which fragments are split into high and low files.
    FragSize=120 
    
    // The size by which Homer clusters it's reads.
    HomerSize=200 
    
    // These should only be changed if your .csv files are not located in your input directory or you want to use
    // a different naming scheme.
    SampleSheet="$params.inputDir/samplesheet*.csv"
    PeakcallingSheet="$params.inputDir/peakcalling*.csv"
    
    // These should only be modified if the reference material changes locations/name or ends up being updated.

    IGV19Genome="/kyukon/data/gent/gvo000/gvo00027/PPOL/resources/repos/IGVTools/genomes/hg19.chrom.sizes"
    HG19Index="/kyukon/data/gent/gvo000/gvo00027/PPOL/resources/ensembl/homo_sapiens/release-75/genome_index/homo_sapiens"
    blackfilter19path="/kyukon/data/gent/gvo000/gvo00027/PPOL/resources/Blacklist_Encode_hg19_nochr.bed"
    
    IGV38Genome="/kyukon/data/gent/gvo000/gvo00027/PPOL/resources/repos/IGVTools/genomes/hg38.chrom.sizes"
    HG38Index="/kyukon/data/gent/gvo000/gvo00027/PPOL/resources/ensembl/homo_sapiens/release-75/genome_index/homo_sapiens"
    blackfilter38path="/kyukon/data/gent/gvo000/gvo00027/PPOL/resources/Blacklist_Encode_hg38_nochr.bed"
    
    // Below are a set of enabling parameters. The pipeline uses these to select the variables declared above
    // in a conditional manner for the different processes depending on the reference (hg19 or hg38) that they require.
    // You should only ever touch these if you're changing the names of the workflows, the processes or the paramaters ABOVE.
    // Formatting is: [Variable in process].'[workflow_name]:[process_name]=[reference_parameter]
    IGVGenome.'hg19:IGV'=IGV19Genome
    BlackFilterPath.'hg19:BlackFiltering'=blackfilter19path
    HGIndex.'hg19:MapFiles'=HG19Index
    hg19Tuple=["hg19",true,false]
    
    IGVGenome.'hg38:IGV'=IGV38Genome
    HGIndex.'hg38:MapFiles'=HG38Index
    BlackFilterPath.'hg38:BlackFiltering'=blackfilter38path
    hg38Tuple=["hg38",false,true]

    big_task_cpus=9
}


// Below are the resources the pipeline requests from the HPC whenever it submits a job.
// These have not been finetuned and as a result all of the processes request more resources than they'll need.


process{
  
  // The job management system that's used to submit processes. 
  // The nextflow documentation contains a list of all the compatible ones.
  executor = "slurm"
  cache = 'lenient'
    
    withLabel: big_task {
      cpus = params.big_task_cpus
      memory = '32 GB'
      time = '4h'
      }
    withLabel: small_task {
      cpus = 2
      memory = '8 GB'
      time = '20m'
      } 
}
